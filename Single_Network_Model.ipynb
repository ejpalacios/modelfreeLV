{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigates different options for preprocessing and ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgJC7bNrzNUR"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21162,
     "status": "ok",
     "timestamp": 1707733523302,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "hGQKOBL9k5UB",
    "outputId": "49ccc9db-d81c-4f89-bef0-b6ec8719db5c"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "sns.set_theme(style = \"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    'font.size': 8,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707733523302,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "Q5C5bPQI0l_D"
   },
   "outputs": [],
   "source": [
    "PLOT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI_HeRdDxy2_"
   },
   "source": [
    "# Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.cwd()\n",
    "print(f\"{base_path=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2622,
     "status": "ok",
     "timestamp": 1707733525922,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "QKOP6eP5Eyb7"
   },
   "outputs": [],
   "source": [
    "with open(base_path.joinpath(\"Simulation_Results_10\").joinpath(\"Loads_Network_1_Feeder_1.npy\"), 'rb') as f:\n",
    "    Dataset = np.load(f, allow_pickle = True)\n",
    "\n",
    "with open(base_path.joinpath(\"Simulation_Results_10\").joinpath(\"Targets_Network_1_Feeder_1.npy\"), \"rb\") as f:\n",
    "    Targets = np.load(f, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707733525923,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "Oi-j0sgN0bVl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Dataset, 230*Targets, test_size=0.3, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_n = np.random.uniform(0.9,0.98,len(X_train[:,0]))\n",
    "phi_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707733525924,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "ZsqdKZ652V1u"
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, axes = plt.subplots(1,1, figsize = (3.15,3.15))\n",
    "    plt.title(f\"Active Power vs. Reactive Power\", fontsize = 8)\n",
    "    plt.ylabel(\"Reactive Power [kVAR]\", fontsize = 8)\n",
    "    plt.xlabel(\"Active Power [kW]\", fontsize = 8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "\n",
    "    sns.scatterplot(x = X_train[:,0], y = X_train[:,0]*np.tan(np.arccos(phi_n)), s = 5, alpha = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707733526293,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "Jl2YES0Q5z7L"
   },
   "outputs": [],
   "source": [
    "names_list = []\n",
    "for i in range(0,55):\n",
    "    names_list.append(f\"{i}\")\n",
    "X_train_df = pd.DataFrame(X_train, columns = names_list)\n",
    "y_train_df =  pd.DataFrame(y_train, columns = [\"y\"])\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test, columns = names_list)\n",
    "y_test_df =  pd.DataFrame(y_test, columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 1119,
     "status": "ok",
     "timestamp": 1707733527405,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "kXMm3JqS0OhR",
    "outputId": "4746c074-f1e3-4eab-cd57-0e961dbbd6c6"
   },
   "outputs": [],
   "source": [
    "# aggregate agisngt voltage\n",
    "sns.scatterplot(x = np.array(X_train_df.sum(axis = 1)), y = np.array(y_train_df)[:,0])\n",
    "plt.xlabel(\"Agragate Load [kW]\")\n",
    "plt.ylabel(\"Voltage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707733527406,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "PLCtGnim6DWy"
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, ax = plt.subplots(1,1, figsize = (6.3,5))\n",
    "    # Compute the correlation matrix\n",
    "    corr = X_train_df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1,vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    Count, Average, Number = 0,0,0\n",
    "    for i in range(55):\n",
    "        for j in range(i):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if np.abs(corr.iloc[i,j]) > 0.3:\n",
    "                Count+=1\n",
    "            Average += np.abs(corr.iloc[i,j])\n",
    "            Number +=1\n",
    "    print(Count)\n",
    "    print(Average/Number)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='major', labelsize=8)\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707733527406,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "q4eOQgs8w9n-"
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    # Set up the matplotlib figure\n",
    "    f, axes = plt.subplots(figsize=(20, 6))\n",
    "    # Using seaborn to create boxplots for each column\n",
    "    sns.violinplot(data=X_train_df.iloc[:,:55], width=1,inner = None)\n",
    "    xyz = X_train_df.iloc[:, :55].copy()\n",
    "    plt.title(f\"Distribution of Loads\",fontsize = 15)\n",
    "    plt.xlabel(\"Loads\",fontsize = 15)\n",
    "    plt.ylabel(\"Active Power [kW]\",fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707733527406,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "EpDiMw5PxKGf",
    "outputId": "a47bb853-552e-4718-aa3e-7764f9758a0b"
   },
   "outputs": [],
   "source": [
    "X_df_transformed = pd.DataFrame(X_train, columns = names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh_o5_AwyibM"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13705,
     "status": "ok",
     "timestamp": 1707733545937,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "an3cWJtJyvwb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import yeojohnson\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2Crcj__VA5x"
   },
   "source": [
    "## Training different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = TransformedTargetRegressor(\n",
    "    regressor = linear_model.LinearRegression(),\n",
    "    transformer = StandardScaler(with_mean = True, with_std = True)\n",
    "    )\n",
    "# Add to pipeline to add c&s or PT and c&s\n",
    "#(\"preprocess_cs\",StandardScaler(with_mean = True, with_std = True)),\n",
    "#(\"preprocess_tr\",PowerTransformer(method = \"yeo-johnson\")),\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"target_transform\", regressor)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voltage Distribution\n",
    "if PLOT:\n",
    "    ss = StandardScaler(with_mean = True, with_std = True).fit(y_train.reshape(-1, 1))\n",
    "    v_transformed = ss.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    p = PowerTransformer(standardize = False).fit(y_train.reshape(-1, 1))\n",
    "    p_t = p.transform(y_train.reshape(-1, 1))\n",
    "    sp = StandardScaler(with_mean = True, with_std = True).fit(p_t)\n",
    "    v_p_transformed = sp.transform(p_t)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize = (6.3,3))\n",
    "    \n",
    "    sns.histplot(y_train, ax = ax[0])\n",
    "    ax[0].set_ylabel(\"Count\", fontsize = 8)\n",
    "    ax[0].set_xlabel(\"Voltage\", fontsize = 8)\n",
    "    ax[0].set_title(f\"Voltage Dist.\", fontsize = 8)\n",
    "    ax[0].set_xlim(215,245)\n",
    "    ax[0].set_ylim(0,380)\n",
    "    ax[0].set_xticks(range(215,250,5))\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax[0].text(0.95, -0.19, \"(a)\", verticalalignment='bottom', horizontalalignment='right',\n",
    "            transform=ax[0].transAxes, fontsize=8)\n",
    "    \n",
    "    sns.histplot(v_transformed.values.flatten(), ax = ax[1])\n",
    "    ax[1].set_ylabel(\"Count\", fontsize = 8)\n",
    "    ax[1].set_xlabel(\"Voltage\", fontsize = 8)\n",
    "    ax[1].set_title(f\"Voltage Dist. with C & S\", fontsize = 8)\n",
    "    ax[1].set_xlim(-5,5)\n",
    "    ax[1].set_ylim(0,380)\n",
    "    ax[1].set_xticks([-5,-2.5,0,2.5,5])\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax[1].text(0.95, -0.19, \"(b)\", verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax[1].transAxes, fontsize=8)\n",
    "    \n",
    "    sns.histplot(v_p_transformed.values.flatten(), ax = ax[2])\n",
    "    ax[2].set_ylabel(\"Count\", fontsize = 8)\n",
    "    ax[2].set_xlabel(\"Voltage\", fontsize = 8)\n",
    "    ax[2].set_title(f\"Voltage Dist. with Power Transform\", fontsize = 8)\n",
    "    ax[2].set_xlim(-3,3)\n",
    "    ax[2].set_ylim(0,380)\n",
    "    ax[2].set_xticks(range(-3,4))\n",
    "    ax[2].tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax[2].text(0.95, -0.19, \"(c)\", verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax[2].transAxes, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    cs_scaler = StandardScaler(with_mean = True, with_std = True)\n",
    "    cs_scaler.fit(X_train)\n",
    "    X_centered = cs_scaler.transform(X_train)\n",
    "    \n",
    "    yeo = PowerTransformer(method = \"yeo-johnson\")\n",
    "    yeo.fit(X_train)\n",
    "    X_centered_trans = yeo.transform(X_train)\n",
    "    \n",
    "    f, axes = plt.subplots(3,1,figsize=(6.3, 6))\n",
    "    #f, axes = plt.subplots(3,1,figsize=(15, 6))\n",
    "    # Using seaborn to create boxplots for each column\n",
    "    sns.violinplot(data=X_train, ax = axes[0], width=1,inner = None, linewidth = 0.5)\n",
    "    axes[0].set_title(\"Distribution of Loads\",fontsize = 8)\n",
    "    axes[0].set_xlabel(\"Customer\",fontsize = 8)\n",
    "    axes[0].set_ylabel(\"Active Power [kW]\",fontsize = 8)\n",
    "    axes[0].set_ylim(-5,15)\n",
    "    axes[0].set_yticks(range(-5,20,5))\n",
    "    axes[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "    axes[0].text(0.95, -0.25, \"(a)\", transform=axes[0].transAxes, fontsize=8, va='top')\n",
    "    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=-90)\n",
    "\n",
    "    sns.violinplot(data=X_centered, ax = axes[1], width=1,inner = None, linewidth = 0.5)\n",
    "    axes[1].set_title(f\"Distribution of Loads after Centering and Scaling\",fontsize = 8)\n",
    "    axes[1].set_xlabel(\"Customer\",fontsize = 8)\n",
    "    axes[1].set_ylabel(\"Active Power [kW]\",fontsize = 8)\n",
    "    axes[1].set_ylim(-5,15)\n",
    "    axes[1].set_yticks(range(-5,20,5))\n",
    "    axes[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "    axes[1].text(0.95, -0.25, \"(b)\", transform=axes[1].transAxes, fontsize=8, va='top')\n",
    "    axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=-90)\n",
    "    \n",
    "    sns.violinplot(data=X_centered_trans, ax = axes[2], width=1,inner = None, linewidth = 0.5)\n",
    "    axes[2].set_title(f\"Distribution of Loads after Power Transform Centering and Scaling\",fontsize = 8)\n",
    "    axes[2].set_xlabel(\"Customer\",fontsize = 8)\n",
    "    axes[2].set_ylabel(\"Active Power [kW]\",fontsize = 8)\n",
    "    axes[2].set_ylim(-10,10)\n",
    "    axes[2].set_yticks(range(-10,15,5))\n",
    "    axes[2].tick_params(axis='both', which='major', labelsize=8)\n",
    "    axes[2].text(0.95, -0.25, \"(c)\", transform=axes[2].transAxes, fontsize=8, va='top')\n",
    "    axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=-90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    \"model__C\": np.logspace(-4, 4, 4),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_train_df, y_train_df)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyUTNnHtu-67"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707746445344,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "Z7JNtZjYg3ZW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared = False), greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbMHLyan3AAy"
   },
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1545153,
     "status": "ok",
     "timestamp": 1707744956528,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "ffz0bhIzvDjn",
    "outputId": "941978f5-b92b-4904-b731-87cd9b84a9e1"
   },
   "outputs": [],
   "source": [
    "pipeline.set_params(target_transform__regressor = SVR(kernel = \"linear\"))\n",
    "\n",
    "param_grid = {\n",
    "'target_transform__regressor__C': np.linspace(1, 10, 10),\n",
    "'target_transform__regressor__epsilon': np.linspace(0, 0.1, 20)\n",
    "}\n",
    "\n",
    "grid_search_lin = GridSearchCV(pipeline, param_grid, cv=RepeatedKFold(n_splits=5, n_repeats=2), scoring=rmse_scorer, n_jobs=-1, verbose = 2)\n",
    "grid_search_lin.fit(X_train, y_train)\n",
    "results_lin_svm = pd.DataFrame(grid_search_lin.cv_results_)\n",
    "results_lin_svm[\"mean_test_score\"] = -1*results_lin_svm[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = sns.pointplot(x='param_target_transform__regressor__C', y='mean_test_score', hue='param_target_transform__regressor__epsilon', data=results_lin_svm, palette = \"viridis\")\n",
    "\n",
    "plt.title('Linear SVM Hyperparameter Tuning')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.legend(title='Epsilon', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "SVM_linear_params = grid_search_lin.best_params_\n",
    "print(grid_search_lin.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbeT3oVhhfu8"
   },
   "source": [
    "## SVM Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 898532,
     "status": "ok",
     "timestamp": 1707750196882,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "GansoFfPhd6F",
    "outputId": "ed439bca-fed0-41d7-c821-b1520cd7f6e6"
   },
   "outputs": [],
   "source": [
    "# gamma is chosen analytically\n",
    "pipeline.set_params(target_transform__regressor = SVR(kernel = \"rbf\"))\n",
    "\n",
    "param_grid = {\n",
    "'target_transform__regressor__C': np.linspace(1, 10, 20),\n",
    "'target_transform__regressor__epsilon': np.linspace(0, 0.01, 20)\n",
    "}\n",
    "\n",
    "grid_search_rbf = GridSearchCV(pipeline, param_grid, cv=RepeatedKFold(n_splits=5, n_repeats=2), scoring=rmse_scorer, n_jobs=-1, verbose = 2)\n",
    "grid_search_rbf.fit(X_train, y_train)\n",
    "results_rbf = pd.DataFrame(grid_search_rbf.cv_results_)\n",
    "results_rbf[\"mean_test_score\"] = -1*results_rbf[\"mean_test_score\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = sns.pointplot(x='param_target_transform__regressor__C', y='mean_test_score', hue='param_target_transform__regressor__epsilon', data=results_rbf, palette = \"viridis\")\n",
    "\n",
    "plt.title('RBF SVM Hyperparameter Tuning')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Negative Root Mean Squared Error')\n",
    "plt.legend(title='Epsilon')\n",
    "plt.show()\n",
    "\n",
    "SVM_rbf_params = grid_search_rbf.best_params_\n",
    "print(grid_search_rbf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZvWcsW5zlxK"
   },
   "source": [
    "## Histogram Gadient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 885677,
     "status": "error",
     "timestamp": 1707757269430,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "z4uxMDJTzwXs",
    "outputId": "b0161bea-bffb-435c-9878-76d35f3a09c9"
   },
   "outputs": [],
   "source": [
    "pipeline.set_params(target_transform__regressor = HistGradientBoostingRegressor(max_iter = 500))\n",
    "\n",
    "param_grid = {\n",
    "'target_transform__regressor__learning_rate': np.linspace(0.01, 0.3, 20),\n",
    "'target_transform__regressor__l2_regularization': np.linspace(0, 5, 3)\n",
    "}\n",
    "\n",
    "grid_search_hist = GridSearchCV(pipeline, param_grid, cv=RepeatedKFold(n_splits=5, n_repeats=2), scoring=rmse_scorer, n_jobs=-1, verbose = 2)\n",
    "grid_search_hist.fit(X_train, y_train)\n",
    "results_hist = pd.DataFrame(grid_search_hist.cv_results_)\n",
    "results_hist[\"mean_test_score\"] = -1*results_hist[\"mean_test_score\"]\n",
    "\n",
    "\n",
    "hist_grad_boost_params = grid_search_hist.best_params_\n",
    "print(grid_search_hist.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.3, 3))\n",
    "ax = sns.pointplot(x='param_target_transform__regressor__learning_rate', y='mean_test_score', errorbar = 'sd', hue='param_target_transform__regressor__l2_regularization', data=results_hist, palette = \"viridis\")\n",
    "\n",
    "plt.title('Histogram Gradient Boosting Regressor Hyperparameter Tuning',fontsize = 8)\n",
    "plt.xlabel('Learning rate',fontsize = 8)\n",
    "ax.set_xticklabels(['{:.2f}'.format(float(t.get_text())) for t in ax.get_xticklabels()],fontsize = 8)\n",
    "ax.set_yticklabels(['{:.2f}'.format(float(t.get_text())) for t in ax.get_yticklabels()],fontsize = 8)\n",
    "plt.ylabel('Root Mean Squared Error',fontsize = 8)\n",
    "leg = plt.legend(title='l2 Regularisation', fontsize = 8)\n",
    "leg.get_title().set_fontsize('8')\n",
    "plt.savefig(\"Images/HistGradBoost_Tuning.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzCBG_ssCA_n"
   },
   "source": [
    "# Neural Network Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 503238,
     "status": "ok",
     "timestamp": 1707758313370,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "0Qe-JbY0M5Y2",
    "outputId": "91962bc2-8541-49bc-fd9d-8b11f0f34d50"
   },
   "outputs": [],
   "source": [
    "pipeline.set_params(target_transform__regressor = MLPRegressor())\n",
    "\n",
    "param_grid = {\n",
    "'target_transform__regressor__learning_rate_init': np.linspace(0.001, 0.1, 20),\n",
    "'target_transform__regressor__alpha': np.linspace(0.00001, 0.001, 20),\n",
    "'target_transform__regressor__hidden_layer_sizes': [[25,], [50,],[100,],[50,50,]]   \n",
    "}\n",
    "\n",
    "grid_search_nn = GridSearchCV(pipeline, param_grid, cv=RepeatedKFold(n_splits=10, n_repeats=5), scoring=rmse_scorer, n_jobs=-1, verbose = 2)\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "results_nn = pd.DataFrame(grid_search_nn.cv_results_)\n",
    "results_nn[\"mean_test_score\"] = -1*results_nn[\"mean_test_score\"]\n",
    "\n",
    "NN_optimal_params = grid_search_nn.best_params_\n",
    "print(grid_search_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn['density_str'] = results_nn['param_target_transform__regressor__hidden_layer_sizes'].astype(str)\n",
    "g = sns.FacetGrid(results_nn, row='density_str', height=3, aspect=4, palette = \"viridis\")\n",
    "\n",
    "# Map the pointplot onto the grid, specifying x, y, and hue\n",
    "g.map(sns.pointplot, 'param_target_transform__regressor__learning_rate_init', 'mean_test_score', 'param_target_transform__regressor__alpha', palette = \"viridis\")\n",
    "\n",
    "# Set plot labels and title\n",
    "g.set_axis_labels('Learning Rate', 'Root Mean Squared Error')\n",
    "g.fig.suptitle('Neural Network Hyperparameter Tuning', y=1.05)\n",
    "\n",
    "g.add_legend(title='Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN:\n",
    "\n",
    "{'target_transform__regressor__alpha': 0.0006352631578947368, 'target_transform__regressor__hidden_layer_sizes': [25], 'target_transform__regressor__learning_rate_init': 0.04268421052631579}\n",
    "\n",
    "HistGradBoostParam:\n",
    "\n",
    "{'target_transform__regressor__l2_regularization': 0.0, 'target_transform__regressor__learning_rate': 0.05578947368421053}\n",
    "\n",
    "SVM RBF\n",
    "\n",
    "{'target_transform__regressor__C': 7.157894736842105, 'target_transform__regressor__epsilon': 0.0010526315789473684}\n",
    "\n",
    "Linear SVM\n",
    "\n",
    "{'target_transform__regressor__C': 10.0, 'target_transform__regressor__epsilon': 0.02631578947368421}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saBkcCdOu60-"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "executionInfo": {
     "elapsed": 230440,
     "status": "ok",
     "timestamp": 1707758991121,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "qk1YRnkUzA0n",
    "outputId": "f44d1347-5b89-4007-bc61-46e99468c975"
   },
   "outputs": [],
   "source": [
    "RMSE_NN = []\n",
    "RMSE_grad_boost = []\n",
    "RMSE_linear = []\n",
    "RMSE_SVM_linear = []\n",
    "RMSE_SVM_rbf = []\n",
    "\n",
    "predictions_NN = []\n",
    "predictions_grad_boost = []\n",
    "predictions_linear = []\n",
    "predictions_SVM_linear = []\n",
    "predictions_SVM_rbf = []\n",
    "\n",
    "\n",
    "kfold = RepeatedKFold(n_splits=10, n_repeats=5)\n",
    "validations = []\n",
    "# Loop through the folds\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(X_train_df, y_train_df)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train_fold = X_train_df.iloc[train_idx].reset_index(drop = True)\n",
    "    y_train_fold = y_train_df.iloc[train_idx].reset_index(drop = True)\n",
    "\n",
    "    X_val_fold = X_train_df.iloc[valid_idx].reset_index(drop = True)\n",
    "    y_val_fold = y_train_df.iloc[valid_idx].reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    pipeline.set_params(target_transform__regressor = MLPRegressor())\n",
    "    pipeline.set_params(target_transform__regressor__alpha = NN_optimal_params[\"target_transform__regressor__alpha\"])\n",
    "    pipeline.set_params(target_transform__regressor__hidden_layer_sizes = NN_optimal_params[\"target_transform__regressor__hidden_layer_sizes\"])\n",
    "    pipeline.set_params(target_transform__regressor__learning_rate_init = NN_optimal_params[\"target_transform__regressor__learning_rate_init\"])\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    preds_NN = pipeline.predict(X_val_fold)\n",
    "\n",
    "    \n",
    "    pipeline.set_params(target_transform__regressor = HistGradientBoostingRegressor())\n",
    "    pipeline.set_params(target_transform__regressor__learning_rate = hist_grad_boost_params[\"target_transform__regressor__learning_rate\"])\n",
    "    pipeline.set_params(target_transform__regressor__l2_regularization = hist_grad_boost_params[\"target_transform__regressor__l2_regularization\"])\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    preds_grad_boost = pipeline.predict(X_val_fold)\n",
    "    \n",
    "    \n",
    "    pipeline.set_params(target_transform__regressor = linear_model.LinearRegression())\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    preds_linear = pipeline.predict(X_val_fold)\n",
    "    \n",
    "    \n",
    "    pipeline.set_params(target_transform__regressor = SVR(kernel = \"linear\"))\n",
    "    pipeline.set_params(target_transform__regressor__C = SVM_linear_params[\"target_transform__regressor__C\"])\n",
    "    pipeline.set_params(target_transform__regressor__epsilon = SVM_linear_params[\"target_transform__regressor__epsilon\"])\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    preds_SVM_linear = pipeline.predict(X_val_fold)\n",
    "    \n",
    "    \n",
    "    pipeline.set_params(target_transform__regressor = SVR(kernel = \"rbf\"))\n",
    "    pipeline.set_params(target_transform__regressor__C = SVM_rbf_params[\"target_transform__regressor__C\"])\n",
    "    pipeline.set_params(target_transform__regressor__epsilon = SVM_rbf_params[\"target_transform__regressor__epsilon\"])\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    preds_SVM_rbf = pipeline.predict(X_val_fold)\n",
    "\n",
    "    RMSE_NN.append(mean_squared_error(y_val_fold, preds_NN, squared=False))\n",
    "    print(f\"RMSE NN: {RMSE_NN[-1]}\")\n",
    "    predictions_NN.append(np.array(preds_NN))\n",
    "\n",
    "    RMSE_grad_boost.append(mean_squared_error(y_val_fold, preds_grad_boost, squared=False))\n",
    "    print(f\"RMSE grad boost: {RMSE_grad_boost[-1]}\")\n",
    "    predictions_grad_boost.append(preds_grad_boost)\n",
    "\n",
    "    RMSE_linear.append(mean_squared_error(y_val_fold, preds_linear, squared=False))\n",
    "    print(f\"RMSE linear: {RMSE_linear[-1]}\")\n",
    "    predictions_linear.append(preds_linear)\n",
    "\n",
    "    RMSE_SVM_linear.append(mean_squared_error(y_val_fold, preds_SVM_linear, squared=False))\n",
    "    print(f\"RMSE SVM linear: {RMSE_SVM_linear[-1]}\")\n",
    "    predictions_SVM_linear.append(preds_SVM_linear)\n",
    "\n",
    "    RMSE_SVM_rbf.append(mean_squared_error(y_val_fold, preds_SVM_rbf, squared=False))\n",
    "    print(f\"RMSE SVM RBF: {RMSE_SVM_rbf[-1]}\")\n",
    "    predictions_SVM_rbf.append(preds_SVM_rbf)\n",
    "\n",
    "    validations.append(y_val_fold)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Fold time taken: {end_time - start_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707758991121,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "83Ngd-3jzFYT",
    "outputId": "25e533b0-0fbf-43e8-d826-6d320038eb4d"
   },
   "outputs": [],
   "source": [
    "print(f\"RMSE NN: Average: {sum(RMSE_NN)/len(RMSE_NN)}\" )\n",
    "print(f\"RMSE grad boost: Average: {sum(RMSE_grad_boost)/len(RMSE_grad_boost)}\" )\n",
    "print(f\"RMSE linear: Average: {sum(RMSE_linear)/len(RMSE_linear)}\" )\n",
    "print(f\"RMSE SVM linear: Average: {sum(RMSE_SVM_linear)/len(RMSE_SVM_linear)}\" )\n",
    "print(f\"RMSE SVM RBF: Average: {sum(RMSE_SVM_rbf)/len(RMSE_SVM_rbf)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4587,
     "status": "ok",
     "timestamp": 1707759004506,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "bSf4Y9LszNkV",
    "outputId": "7d2cacbe-be84-4e44-e76c-a16a1b855485"
   },
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"husl\", 6)\n",
    "fig, axes = plt.subplots(len(validations),1, figsize = (18,20))\n",
    "axes[0].set_title('Predicted Voltage vs Simulated Voltage using a neural network',fontsize = 15)\n",
    "\n",
    "#AveError = []\n",
    "#text = [\"(a)\",\"(b)\",\"(c)\",\"(d)\",\"(e)\"]\n",
    "for i in range(len(validations)):\n",
    "\n",
    "    sns.lineplot(ax = axes[i], data = validations[i].values.flatten(), label = \"true\", color = palette[0])\n",
    "    sns.lineplot(ax = axes[i], data = predictions_NN[i].flatten(), label = \"NN\", color = palette[1])\n",
    "    sns.lineplot(ax = axes[i], data = predictions_grad_boost[i].flatten(), label = \"grad boost\", color = palette[2])\n",
    "    sns.lineplot(ax = axes[i], data = predictions_linear[i].flatten(), label = \"linear\", color = palette[3])\n",
    "    sns.lineplot(ax = axes[i], data = predictions_SVM_linear[i].flatten(), label = \"linear SVM\", color = palette[4])\n",
    "    sns.lineplot(ax = axes[i], data = predictions_SVM_rbf[i].flatten(), label = \"rbf\", color = palette[5])\n",
    "\n",
    "    axes[i].set_ylabel(\"Voltage\",fontsize = 15)\n",
    "    axes[i].set_xlabel(\"Samples\",fontsize = 15)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1707758991597,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "YH3W40PmzXlJ",
    "outputId": "1e427583-c281-4f83-ed80-486358e28e0f"
   },
   "outputs": [],
   "source": [
    "RMSEs = pd.DataFrame([RMSE_NN, RMSE_grad_boost, RMSE_linear,RMSE_SVM_linear,RMSE_SVM_rbf], index=['NN', 'Light GBM', 'Linear','Linear SVM', 'RBF SVM'])\n",
    "\n",
    "sns.boxplot(data = RMSEs.transpose(), color = \"white\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.savefig(\"Images/selection_box.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "executionInfo": {
     "elapsed": 4123,
     "status": "ok",
     "timestamp": 1707758995717,
     "user": {
      "displayName": "Anthony Gerard O'Malley",
      "userId": "08354629277054091219"
     },
     "user_tz": 0
    },
    "id": "az_H0ihAfqol",
    "outputId": "089cd2b7-1fd1-4b56-ea21-ed27f291df5d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize = (18,8))\n",
    "for i in range(len(validations)):\n",
    "    sns.scatterplot(ax = axes[0][0], x = validations[i].values.flatten(),y = predictions_NN[i].flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][1], x = validations[i].values.flatten(),y = predictions_grad_boost[i].flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][2], x = validations[i].values.flatten(),y = predictions_linear[i].flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][3], x = validations[i].values.flatten(),y = predictions_SVM_linear[i].flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][4], x = validations[i].values.flatten(),y = predictions_SVM_rbf[i].flatten(), alpha = 0.1, color = \"black\")\n",
    "\n",
    "    sns.scatterplot(ax = axes[1][0], x = predictions_NN[i].flatten(), y = predictions_NN[i].flatten()-validations[i].values.flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][1], x = predictions_grad_boost[i].flatten(),y = predictions_grad_boost[i].flatten()-validations[i].values.flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][2], x = predictions_linear[i].flatten(),y = predictions_linear[i].flatten()-validations[i].values.flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][3], x = predictions_SVM_linear[i].flatten(),y = predictions_SVM_linear[i].flatten()-validations[i].values.flatten(), alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][4], x = predictions_SVM_rbf[i].flatten(),y = predictions_SVM_rbf[i].flatten()-validations[i].values.flatten(), alpha = 0.1, color = \"black\")\n",
    "\n",
    "# set common elements\n",
    "for i in range(5):\n",
    "    axes[0][i].set_ylabel(\"Predicted Voltage\")\n",
    "    axes[0][i].set_xlabel(\"Observed Voltage\")\n",
    "    axes[0][i].set_xlim(228,242)\n",
    "    axes[0][i].set_ylim(228,242)\n",
    "\n",
    "    sns.lineplot(ax = axes[0][i], x = [0,250], y = [0,250], alpha = 0.5, color = \"black\")\n",
    "    axes[0][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "    axes[1][i].set_ylabel(\"Voltage Error\")\n",
    "    axes[1][i].set_xlabel(\"Predicted Voltage\")\n",
    "    axes[1][i].set_xlim(228,242)\n",
    "    axes[1][i].set_ylim(-4,6)\n",
    "\n",
    "    sns.lineplot(ax = axes[1][i], x = [0,250], y = [0,0], alpha = 0.5, color = \"black\")\n",
    "    axes[1][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "axes[0][0].set_title(\"Neural Network\")\n",
    "axes[0][1].set_title(\"Light GBM\")\n",
    "axes[0][2].set_title(\"Linear Regression\")\n",
    "axes[0][3].set_title(\"Linear SVM\")\n",
    "axes[0][4].set_title(\"RBF SVM\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test linear on 30\n",
    "with open(f\"Simulation_Results_30/Loads_Network_1_Feeder_1.npy\", 'rb') as f:\n",
    "    Dataset_30 = np.load(f, allow_pickle = True)\n",
    "\n",
    "with open(f\"Simulation_Results_30/Targets_Network_1_Feeder_1.npy\", \"rb\") as f:\n",
    "    Targets_30 = np.load(f, allow_pickle = True)\n",
    "\n",
    "\n",
    "# test linear on 50\n",
    "with open(f\"Simulation_Results_50/Loads_Network_1_Feeder_1.npy\", 'rb') as f:\n",
    "    Dataset_50 = np.load(f, allow_pickle = True)\n",
    "\n",
    "with open(f\"Simulation_Results_50/Targets_Network_1_Feeder_1.npy\", \"rb\") as f:\n",
    "    Targets_50 = np.load(f, allow_pickle = True)\n",
    "\n",
    "# test linear on 70\n",
    "with open(f\"Simulation_Results_70/Loads_Network_1_Feeder_1.npy\", 'rb') as f:\n",
    "    Dataset_70 = np.load(f, allow_pickle = True)\n",
    "\n",
    "with open(f\"Simulation_Results_70/Targets_Network_1_Feeder_1.npy\", \"rb\") as f:\n",
    "    Targets_70 = np.load(f, allow_pickle = True)\n",
    "\n",
    "# test linear on 100\n",
    "with open(f\"Simulation_Results_100/Loads_Network_1_Feeder_1.npy\", 'rb') as f:\n",
    "    Dataset_100 = np.load(f, allow_pickle = True)\n",
    "\n",
    "with open(f\"Simulation_Results_100/Targets_Network_1_Feeder_1.npy\", \"rb\") as f:\n",
    "    Targets_100 = np.load(f, allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Neural Network\n",
    "pipeline.set_params(target_transform__regressor = MLPRegressor())\n",
    "pipeline.set_params(target_transform__regressor__alpha = NN_optimal_params[\"target_transform__regressor__alpha\"])\n",
    "pipeline.set_params(target_transform__regressor__hidden_layer_sizes = NN_optimal_params[\"target_transform__regressor__hidden_layer_sizes\"])\n",
    "pipeline.set_params(target_transform__regressor__learning_rate_init = NN_optimal_params[\"target_transform__regressor__learning_rate_init\"])\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds_NN_10 = pipeline.predict(X_test)\n",
    "preds_NN_30 = pipeline.predict(Dataset_30)\n",
    "preds_NN_50 = pipeline.predict(Dataset_50)\n",
    "preds_NN_70 = pipeline.predict(Dataset_70)\n",
    "preds_NN_100 = pipeline.predict(Dataset_100)\n",
    "\n",
    "# HistGradBoost\n",
    "pipeline.set_params(target_transform__regressor = HistGradientBoostingRegressor())\n",
    "pipeline.set_params(target_transform__regressor__learning_rate = hist_grad_boost_params[\"target_transform__regressor__learning_rate\"])\n",
    "pipeline.set_params(target_transform__regressor__l2_regularization = hist_grad_boost_params[\"target_transform__regressor__l2_regularization\"])\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds_grad_boost_10 = pipeline.predict(X_test)\n",
    "preds_grad_boost_30 = pipeline.predict(Dataset_30)\n",
    "preds_grad_boost_50 = pipeline.predict(Dataset_50)\n",
    "preds_grad_boost_70 = pipeline.predict(Dataset_70)\n",
    "preds_grad_boost_100 = pipeline.predict(Dataset_100)\n",
    "\n",
    "pipeline.set_params(target_transform__regressor = linear_model.LinearRegression())\n",
    "pipeline.fit(X_train, y_train)\n",
    "#print(pipeline.named_steps['target_transform'].regressor_.coef_)\n",
    "#print(pipeline.named_steps['target_transform'].regressor_.intercept_)\n",
    "preds_linear_10 = pipeline.predict(X_test)\n",
    "preds_linear_30 = pipeline.predict(Dataset_30)\n",
    "preds_linear_50 = pipeline.predict(Dataset_50)\n",
    "preds_linear_70 = pipeline.predict(Dataset_70)\n",
    "preds_linear_100 = pipeline.predict(Dataset_100)\n",
    "\n",
    "pipeline.set_params(target_transform__regressor = SVR(kernel = \"linear\"))\n",
    "pipeline.set_params(target_transform__regressor__C = SVM_linear_params[\"target_transform__regressor__C\"])\n",
    "pipeline.set_params(target_transform__regressor__epsilon = SVM_linear_params[\"target_transform__regressor__epsilon\"])\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds_SVM_linear_10 = pipeline.predict(X_test)\n",
    "preds_SVM_linear_30 = pipeline.predict(Dataset_30)\n",
    "preds_SVM_linear_50 = pipeline.predict(Dataset_50)\n",
    "preds_SVM_linear_70 = pipeline.predict(Dataset_70)\n",
    "preds_SVM_linear_100 = pipeline.predict(Dataset_100)\n",
    "\n",
    "pipeline.set_params(target_transform__regressor = SVR(kernel = \"rbf\"))\n",
    "pipeline.set_params(target_transform__regressor__C = SVM_rbf_params[\"target_transform__regressor__C\"])\n",
    "pipeline.set_params(target_transform__regressor__epsilon = SVM_rbf_params[\"target_transform__regressor__epsilon\"])\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds_SVM_rbf_10 = pipeline.predict(X_test)\n",
    "preds_SVM_rbf_30 = pipeline.predict(Dataset_30)\n",
    "preds_SVM_rbf_50 = pipeline.predict(Dataset_50)\n",
    "preds_SVM_rbf_70 = pipeline.predict(Dataset_70)\n",
    "preds_SVM_rbf_100 = pipeline.predict(Dataset_100)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"time taken: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize = (18,8))\n",
    "for i in range(len(validations)):\n",
    "    sns.scatterplot(ax = axes[0][0], x = y_test, y = preds_NN, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][1], x = y_test, y = preds_grad_boost, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][2], x = y_test, y = preds_linear, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][3], x = y_test, y = preds_SVM_linear, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][4], x = y_test, y = preds_SVM_rbf, alpha = 0.1, color = \"black\")\n",
    "\n",
    "    sns.scatterplot(ax = axes[1][0], x = preds_NN, y = preds_NN-y_test, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][1], x = preds_grad_boost, y = preds_grad_boost-y_test, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][2], x = preds_linear, y = preds_linear-y_test, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][3], x = preds_SVM_linear, y = preds_SVM_linear-y_test, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][4], x = preds_SVM_rbf, y = preds_SVM_rbf-y_test, alpha = 0.1, color = \"black\")\n",
    "\n",
    "# set common elements\n",
    "for i in range(5):\n",
    "    axes[0][i].set_ylabel(\"Predicted Voltage\")\n",
    "    axes[0][i].set_xlabel(\"Observed Voltage\")\n",
    "    axes[0][i].set_xlim(225,242)\n",
    "    axes[0][i].set_ylim(225,242)\n",
    "\n",
    "    sns.lineplot(ax = axes[0][i], x = [0,250], y = [0,250])\n",
    "    axes[0][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "    axes[1][i].set_ylabel(\"Voltage Error\")\n",
    "    axes[1][i].set_xlabel(\"Predicted Voltage\")\n",
    "    axes[1][i].set_xlim(225,242)\n",
    "    axes[1][i].set_ylim(-4,6)\n",
    "\n",
    "    sns.lineplot(ax = axes[1][i], x = [0,250], y = [0,0])\n",
    "    axes[1][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "axes[0][0].set_title(\"Neural Network\")\n",
    "axes[0][1].set_title(\"Light GBM\")\n",
    "axes[0][2].set_title(\"Linear Regression\")\n",
    "axes[0][3].set_title(\"Linear SVM\")\n",
    "axes[0][4].set_title(\"RBF SVM\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot error\n",
    "fig, axes = plt.subplots(5,1, figsize = (18,15))\n",
    "axes[0].set_title(\"Linear\")\n",
    "sns.violinplot(ax = axes[0], data = [preds_linear_10-y_test, preds_linear_30-230*Targets_30, preds_linear_50-230*Targets_50, preds_linear_70-230*Targets_70, preds_linear_100-230*Targets_100])\n",
    "axes[0].set_xticks(ticks = range(5), labels = [\"10% EV and PV\",\"30% EV and PV\",\"50% EV and PV\",\"70% EV and PV\",\"100% EV and PV\"])\n",
    "\n",
    "\n",
    "axes[1].set_title(\"Linear SVM\")\n",
    "sns.violinplot(ax = axes[1], data = [preds_SVM_linear_10-y_test, preds_SVM_linear_30-230*Targets_30, preds_SVM_linear_50-230*Targets_50, preds_SVM_linear_70-230*Targets_70,preds_SVM_linear_100-230*Targets_100])\n",
    "axes[1].set_xticks(ticks = range(5), labels = [\"10% EV and PV\",\"30% EV and PV\",\"50% EV and PV\",\"70% EV and PV\",\"100% EV and PV\"])\n",
    "\n",
    "axes[2].set_title(\"Neural Network\")\n",
    "sns.violinplot(ax = axes[2], data = [preds_NN_10-y_test, preds_NN_30-230*Targets_30, preds_NN_50-230*Targets_50, preds_NN_70-230*Targets_70,preds_NN_100-230*Targets_100])\n",
    "axes[2].set_xticks(ticks = range(5), labels = [\"10% EV and PV\",\"30% EV and PV\",\"50% EV and PV\",\"70% EV and PV\",\"100% EV and PV\"])\n",
    "\n",
    "\n",
    "axes[3].set_title(\"Histogram Gradient Boosting Machine\")\n",
    "sns.violinplot(ax = axes[3], data = [preds_grad_boost_10-y_test, preds_grad_boost_30-230*Targets_30, preds_grad_boost_50-230*Targets_50, preds_grad_boost_70-230*Targets_70,preds_grad_boost_100-230*Targets_100])\n",
    "axes[3].set_xticks(ticks = range(5), labels = [\"10% EV and PV\",\"30% EV and PV\",\"50% EV and PV\",\"70% EV and PV\",\"100% EV and PV\"])\n",
    "\n",
    "\n",
    "axes[4].set_title(\"RBF SVM\")\n",
    "sns.violinplot(ax = axes[4], data = [preds_SVM_rbf_10-y_test, preds_SVM_rbf_30-230*Targets_30, preds_SVM_rbf_50-230*Targets_50, preds_SVM_rbf_70-230*Targets_70,preds_SVM_rbf_100-230*Targets_100])\n",
    "axes[4].set_xticks(ticks = range(5), labels = [\"10% EV and PV\",\"30% EV and PV\",\"50% EV and PV\",\"70% EV and PV\",\"100% EV and PV\"])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize = (18,8))\n",
    "for i in range(len(validations)):\n",
    "    sns.scatterplot(ax = axes[0][0], x = 230*Targets_100, y = preds_NN_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][1], x = 230*Targets_100, y = preds_grad_boost_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][2], x = 230*Targets_100, y = preds_linear_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][3], x = 230*Targets_100, y = preds_SVM_linear_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[0][4], x = 230*Targets_100, y = preds_SVM_rbf_100, alpha = 0.1, color = \"black\")\n",
    "\n",
    "    sns.scatterplot(ax = axes[1][0], x = preds_NN_100, y = preds_NN_100-230*Targets_100, alpha = 0.9, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][1], x = preds_grad_boost_100, y = preds_grad_boost_100-230*Targets_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][2], x = preds_linear_100, y = preds_linear_100-230*Targets_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][3], x = preds_SVM_linear_100, y = preds_SVM_linear_100-230*Targets_100, alpha = 0.1, color = \"black\")\n",
    "    sns.scatterplot(ax = axes[1][4], x = preds_SVM_rbf_100, y = preds_SVM_rbf_100-230*Targets_100, alpha = 0.1, color = \"black\")\n",
    "\n",
    "# set common elements\n",
    "for i in range(5):\n",
    "    axes[0][i].set_ylabel(\"Predicted Voltage\")\n",
    "    axes[0][i].set_xlabel(\"Observed Voltage\")\n",
    "    axes[0][i].set_xlim(210,260)\n",
    "    axes[0][i].set_ylim(210,260)\n",
    "\n",
    "    sns.lineplot(ax = axes[0][i], x = [0,300], y = [0,300])\n",
    "    axes[0][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "    axes[1][i].set_ylabel(\"Voltage Error\")\n",
    "    axes[1][i].set_xlabel(\"Predicted Voltage\")\n",
    "    axes[1][i].set_xlim(210,260)\n",
    "    axes[1][i].set_ylim(-8,8)\n",
    "\n",
    "    sns.lineplot(ax = axes[1][i], x = [0,300], y = [0,0])\n",
    "    axes[1][i].lines[0].set_linestyle(\"--\")\n",
    "\n",
    "\n",
    "axes[0][0].set_title(\"Neural Network\")\n",
    "axes[0][1].set_title(\"Light GBM\")\n",
    "axes[0][2].set_title(\"Linear Regression\")\n",
    "axes[0][3].set_title(\"Linear SVM\")\n",
    "axes[0][4].set_title(\"RBF SVM\")\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\n",
    "NN_optimal_params = {'target_transform__regressor__alpha': 0.0006352631578947368, 'target_transform__regressor__hidden_layer_sizes': [25], 'target_transform__regressor__learning_rate_init': 0.04268421052631579}\n",
    "\n",
    "hist_grad_boost_params = {'target_transform__regressor__l2_regularization': 0.0, 'target_transform__regressor__learning_rate': 0.05578947368421053}\n",
    "\n",
    "SVM_rbf_params = {'target_transform__regressor__C': 7.157894736842105, 'target_transform__regressor__epsilon': 0.0010526315789473684}\n",
    "\n",
    "SVM_linear_params = {'target_transform__regressor__C': 10.0, 'target_transform__regressor__epsilon': 0.02631578947368421}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor1 = TransformedTargetRegressor(\n",
    "    regressor = linear_model.LinearRegression(),\n",
    "    #transformer = StandardScaler(with_mean = True, with_std = True)\n",
    "    )\n",
    "regressor2 = TransformedTargetRegressor(\n",
    "    regressor = linear_model.LinearRegression(),\n",
    "    transformer = StandardScaler(with_mean = True, with_std = True)\n",
    "    )\n",
    "\n",
    "# nothing\n",
    "pipeline1 = Pipeline(\n",
    "    steps = [\n",
    "        (\"target_transform\", regressor1)\n",
    "    ])\n",
    "# c and s\n",
    "pipeline2 = Pipeline(\n",
    "    steps = [\n",
    "        (\"preprocess_cs\", StandardScaler(with_mean = True, with_std = True)),\n",
    "        (\"target_transform\", regressor2)\n",
    "    ])\n",
    "# power transform c and s\n",
    "pipeline3 = Pipeline(\n",
    "    steps = [\n",
    "        (\"preprocess_tr\", PowerTransformer(method = \"yeo-johnson\")),\n",
    "        (\"target_transform\", regressor2)\n",
    "    ])\n",
    "\n",
    "pipelines = [pipeline1,pipeline2,pipeline3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_NN = []\n",
    "predictions_grad_boost = []\n",
    "predictions_linear = []\n",
    "predictions_SVM_linear = []\n",
    "predictions_SVM_rbf = []\n",
    "ans = []\n",
    "for pipeline in pipelines:\n",
    "    kfold = RepeatedKFold(n_splits=10, n_repeats=2)\n",
    "    RMSE_NN = []\n",
    "    RMSE_grad_boost = []\n",
    "    RMSE_linear = []\n",
    "    RMSE_SVM_linear = []\n",
    "    RMSE_SVM_rbf = []\n",
    "    # Loop through the folds\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(X_train_df, y_train_df)):\n",
    "        print(f\"Fold {fold+1}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        X_train_fold = X_train_df.iloc[train_idx].reset_index(drop = True)\n",
    "        y_train_fold = y_train_df.iloc[train_idx].reset_index(drop = True)\n",
    "\n",
    "        X_val_fold = X_train_df.iloc[valid_idx].reset_index(drop = True)\n",
    "        y_val_fold = y_train_df.iloc[valid_idx].reset_index(drop = True)\n",
    "\n",
    "\n",
    "        pipeline.set_params(target_transform__regressor = MLPRegressor())\n",
    "        pipeline.set_params(target_transform__regressor__alpha = NN_optimal_params[\"target_transform__regressor__alpha\"])\n",
    "        pipeline.set_params(target_transform__regressor__hidden_layer_sizes = NN_optimal_params[\"target_transform__regressor__hidden_layer_sizes\"])\n",
    "        pipeline.set_params(target_transform__regressor__learning_rate_init = NN_optimal_params[\"target_transform__regressor__learning_rate_init\"])\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        preds_NN = pipeline.predict(X_val_fold)\n",
    "\n",
    "\n",
    "        pipeline.set_params(target_transform__regressor = HistGradientBoostingRegressor())\n",
    "        pipeline.set_params(target_transform__regressor__learning_rate = hist_grad_boost_params[\"target_transform__regressor__learning_rate\"])\n",
    "        pipeline.set_params(target_transform__regressor__l2_regularization = hist_grad_boost_params[\"target_transform__regressor__l2_regularization\"])\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        preds_grad_boost = pipeline.predict(X_val_fold)\n",
    "\n",
    "\n",
    "        pipeline.set_params(target_transform__regressor = linear_model.LinearRegression())\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        preds_linear = pipeline.predict(X_val_fold)\n",
    "\n",
    "\n",
    "        pipeline.set_params(target_transform__regressor = SVR(kernel = \"linear\"))\n",
    "        pipeline.set_params(target_transform__regressor__C = SVM_linear_params[\"target_transform__regressor__C\"])\n",
    "        pipeline.set_params(target_transform__regressor__epsilon = SVM_linear_params[\"target_transform__regressor__epsilon\"])\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        preds_SVM_linear = pipeline.predict(X_val_fold)\n",
    "\n",
    "\n",
    "        pipeline.set_params(target_transform__regressor = SVR(kernel = \"rbf\"))\n",
    "        pipeline.set_params(target_transform__regressor__C = SVM_rbf_params[\"target_transform__regressor__C\"])\n",
    "        pipeline.set_params(target_transform__regressor__epsilon = SVM_rbf_params[\"target_transform__regressor__epsilon\"])\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        preds_SVM_rbf = pipeline.predict(X_val_fold)\n",
    "\n",
    "        RMSE_NN.append(mean_squared_error(y_val_fold, preds_NN, squared=False))\n",
    "        #print(f\"RMSE NN: {RMSE_NN[-1]}\")\n",
    "        predictions_NN.append(np.array(preds_NN))\n",
    "\n",
    "        RMSE_grad_boost.append(mean_squared_error(y_val_fold, preds_grad_boost, squared=False))\n",
    "        #print(f\"RMSE grad boost: {RMSE_grad_boost[-1]}\")\n",
    "        predictions_grad_boost.append(preds_grad_boost)\n",
    "\n",
    "        RMSE_linear.append(mean_squared_error(y_val_fold, preds_linear, squared=False))\n",
    "        #print(f\"RMSE linear: {RMSE_linear[-1]}\")\n",
    "        predictions_linear.append(preds_linear)\n",
    "\n",
    "        RMSE_SVM_linear.append(mean_squared_error(y_val_fold, preds_SVM_linear, squared=False))\n",
    "        #print(f\"RMSE SVM linear: {RMSE_SVM_linear[-1]}\")\n",
    "        predictions_SVM_linear.append(preds_SVM_linear)\n",
    "\n",
    "        RMSE_SVM_rbf.append(mean_squared_error(y_val_fold, preds_SVM_rbf, squared=False))\n",
    "        #print(f\"RMSE SVM RBF: {RMSE_SVM_rbf[-1]}\")\n",
    "        predictions_SVM_rbf.append(preds_SVM_rbf)\n",
    "\n",
    "        validations.append(y_val_fold)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Fold time taken: {end_time - start_time:.2f}s\")\n",
    "    \n",
    "    ans.append([RMSE_NN, RMSE_grad_boost, RMSE_linear,RMSE_SVM_linear,RMSE_SVM_rbf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and text models with C and s and power transform\n",
    "fig, ax = plt.subplots(1,5, figsize = (6.3,2.5))\n",
    "sns.set(style=\"whitegrid\", rc={\"lines.linewidth\": 0.7})\n",
    "#NN\n",
    "#for i in ans\n",
    "sns.pointplot(ax = ax[0], data = np.array(ans)[:,0].T, errorbar = \"sd\")\n",
    "sns.pointplot(ax = ax[1], data = np.array(ans)[:,1].T, errorbar = \"sd\")\n",
    "sns.pointplot(ax = ax[2], data = np.array(ans)[:,2].T, errorbar = \"sd\")\n",
    "sns.pointplot(ax = ax[3], data = np.array(ans)[:,3].T, errorbar = \"sd\")\n",
    "sns.pointplot(ax = ax[4], data = np.array(ans)[:,4].T, errorbar = \"sd\")\n",
    "\n",
    "ax[0].set_ylim(0,2)\n",
    "ax[1].set_ylim(0,2)\n",
    "ax[2].set_ylim(0,2)\n",
    "ax[3].set_ylim(0,2)\n",
    "ax[4].set_ylim(0,2)\n",
    "ax[0].set_ylabel(\"RMSE\", fontsize = 8)\n",
    "ax[1].set_ylabel(\"RMSE\", fontsize = 8)\n",
    "ax[2].set_ylabel(\"RMSE\", fontsize = 8)\n",
    "ax[3].set_ylabel(\"RMSE\", fontsize = 8)\n",
    "ax[4].set_ylabel(\"RMSE\", fontsize = 8)\n",
    "\n",
    "ax[0].set_title(\"Neural Network\", fontsize = 8)\n",
    "ax[1].set_title(\"Grad Boost\", fontsize = 8)\n",
    "ax[2].set_title(\"Linear\", fontsize = 8)\n",
    "ax[3].set_title(\"Linear SVR\", fontsize = 8)\n",
    "ax[4].set_title(\"RBF SVR\", fontsize = 8)\n",
    "\n",
    "fig_range = [0,0.5,1,1.5,2]\n",
    "ax[0].set_yticks(fig_range, fig_range, fontsize=8)\n",
    "ax[1].set_yticks(fig_range, fig_range, fontsize=8)\n",
    "ax[2].set_yticks(fig_range, fig_range, fontsize=8)\n",
    "ax[3].set_yticks(fig_range, fig_range, fontsize=8)\n",
    "ax[4].set_yticks(fig_range, fig_range, fontsize=8)\n",
    "\n",
    "ax[0].set_xticks([0,1,2], [\"None\", \"C&S\", \"T&C&S\"], fontsize=8, rotation = -90)\n",
    "ax[1].set_xticks([0,1,2], [\"None\", \"C&S\", \"T&C&S\"], fontsize=8, rotation = -90)\n",
    "ax[2].set_xticks([0,1,2], [\"None\", \"C&S\", \"T&C&S\"], fontsize=8, rotation = -90)\n",
    "ax[3].set_xticks([0,1,2], [\"None\", \"C&S\", \"T&C&S\"], fontsize=8, rotation = -90)\n",
    "ax[4].set_xticks([0,1,2], [\"None\", \"C&S\", \"T&C&S\"], fontsize=8, rotation = -90)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Images/preprocess_select.svg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM9Q4n+Jr4Te6qSzROa4V10",
   "collapsed_sections": [
    "TyUTNnHtu-67",
    "KzCBG_ssCA_n"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
